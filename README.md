# Prompt Evaluation Cases

This repository includes a series of comparative prompt tests across different large language models (LLMs), such as GPT-4, Claude, Gemini, and Mistral.  
Each case focuses on how models interpret the same instruction in different contexts (English and Spanish), highlighting differences in:

- Output clarity
- Factual consistency
- Tone and cultural sensitivity
- Instruction following
- Ethical alignment

The goal is to show how prompt design impacts output behavior across models.

ðŸ“‚ The cases/ folder includes manually curated evaluations and annotations based on real-world prompts.
These samples serve as practical datasets for comparing model behavior in terms of clarity, tone, factuality, and ethics.

ðŸ§ª Ongoing updates will include more multilingual and domain-specific examples (legal, medical, statistical).
